{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import chess\n",
    "import chess.svg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cairosvg import svg2png\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# def board_to_tensor(board):\n",
    "#     piece_to_index = {\n",
    "#         'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "#         'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11\n",
    "#     }\n",
    "#     tensor = torch.zeros(12, 8, 8)\n",
    "#     for square, piece in board.piece_map().items():\n",
    "#         rank, file = divmod(square, 8)\n",
    "#         tensor[piece_to_index[piece.symbol()]][7-rank][file] = 1\n",
    "#     return tensor\n",
    "\n",
    "# def create_influence_channels(board_tensor):\n",
    "#     influence_channels = torch.zeros(12, 8, 8)\n",
    "    \n",
    "#     # Pawn influences\n",
    "#     white_pawn = board_tensor[0]\n",
    "#     black_pawn = board_tensor[6]\n",
    "#     influence_channels[0, :-1, 1:] += white_pawn[1:, :-1]  # Diagonal right\n",
    "#     influence_channels[0, :-1, :-1] += white_pawn[1:, 1:]  # Diagonal left\n",
    "#     influence_channels[6, 1:, 1:] += black_pawn[:-1, :-1]  # Diagonal right\n",
    "#     influence_channels[6, 1:, :-1] += black_pawn[:-1, 1:]  # Diagonal left\n",
    "    \n",
    "#     # Knight influences\n",
    "#     knight_kernel = torch.tensor([\n",
    "#         [0,1,0,1,0],\n",
    "#         [1,0,0,0,1],\n",
    "#         [0,0,0,0,0],\n",
    "#         [1,0,0,0,1],\n",
    "#         [0,1,0,1,0]\n",
    "#     ]).float()\n",
    "#     influence_channels[1] = torch.nn.functional.conv2d(board_tensor[1].unsqueeze(0).unsqueeze(0), knight_kernel.unsqueeze(0).unsqueeze(0), padding=2)[0, 0]\n",
    "#     influence_channels[7] = torch.nn.functional.conv2d(board_tensor[7].unsqueeze(0).unsqueeze(0), knight_kernel.unsqueeze(0).unsqueeze(0), padding=2)[0, 0]\n",
    "    \n",
    "#     # Sliding piece influences (Bishop, Rook, Queen)\n",
    "#     for i, directions in enumerate([(1,1), (1,0), (1,1)]):  # Bishop, Rook, Queen\n",
    "#         white_influence = torch.zeros(8, 8)\n",
    "#         black_influence = torch.zeros(8, 8)\n",
    "#         for dx, dy in [directions, (-directions[0], directions[1]), (directions[0], -directions[1]), (-directions[0], -directions[1])]:\n",
    "#             ray = torch.zeros(8, 8)\n",
    "#             x, y = 3, 3\n",
    "#             while 0 <= x < 8 and 0 <= y < 8:\n",
    "#                 ray[x, y] = 1\n",
    "#                 x, y = x + dx, y + dy\n",
    "#             white_influence += torch.nn.functional.conv2d(board_tensor[i+2].unsqueeze(0).unsqueeze(0), ray.unsqueeze(0).unsqueeze(0), padding='same')[0, 0]\n",
    "#             black_influence += torch.nn.functional.conv2d(board_tensor[i+8].unsqueeze(0).unsqueeze(0), ray.unsqueeze(0).unsqueeze(0), padding='same')[0, 0]\n",
    "#         influence_channels[i+2] = white_influence\n",
    "#         influence_channels[i+8] = black_influence\n",
    "    \n",
    "#     # King influences\n",
    "#     king_kernel = torch.tensor([\n",
    "#         [1,1,1],\n",
    "#         [1,0,1],\n",
    "#         [1,1,1]\n",
    "#     ]).float()\n",
    "#     influence_channels[5] = torch.nn.functional.conv2d(board_tensor[5].unsqueeze(0).unsqueeze(0), king_kernel.unsqueeze(0).unsqueeze(0), padding=1)[0, 0]\n",
    "#     influence_channels[11] = torch.nn.functional.conv2d(board_tensor[11].unsqueeze(0).unsqueeze(0), king_kernel.unsqueeze(0).unsqueeze(0), padding=1)[0, 0]\n",
    "    \n",
    "#     return influence_channels\n",
    "\n",
    "# def combine_influences(influence_channels):\n",
    "#     white_influence = influence_channels[:6].sum(dim=0)\n",
    "#     black_influence = influence_channels[6:].sum(dim=0)\n",
    "    \n",
    "#     # Calculate total influence and control\n",
    "#     total_influence = white_influence + black_influence\n",
    "#     control = torch.tanh(white_influence - black_influence)\n",
    "    \n",
    "#     return total_influence, control\n",
    "\n",
    "# def create_jepa_mask(influence_map, mask_ratio=0.25):\n",
    "#     num_squares = influence_map.numel()\n",
    "#     num_masked = int(num_squares * mask_ratio)\n",
    "#     _, indices = torch.topk(influence_map.flatten(), k=num_masked)\n",
    "#     mask = torch.ones_like(influence_map, dtype=torch.bool)\n",
    "#     mask.view(-1)[indices] = False\n",
    "# # return mask\n",
    "def board_to_tensor(board):\n",
    "    piece_to_index = {'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "                      'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11}\n",
    "    tensor = torch.zeros(13, 8, 8, dtype=torch.float32)\n",
    "    for square, piece in board.piece_map().items():\n",
    "        rank, file = divmod(square, 8)\n",
    "        tensor[piece_to_index[piece.symbol()]][7-rank][file] = 1\n",
    "    \n",
    "    # Add a channel for empty squares\n",
    "    tensor[12] = 1 - tensor.sum(dim=0)\n",
    "    \n",
    "    # Add channels for color-agnostic piece positions and side to move\n",
    "    tensor = torch.cat([\n",
    "        tensor,\n",
    "        tensor[:6] + tensor[6:12],\n",
    "        torch.full((1, 8, 8), float(board.turn))\n",
    "    ], dim=0)\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "def create_influence_channels(board_tensor):\n",
    "    influence_channels = torch.zeros(14, 8, 8, dtype=torch.float32)\n",
    "    \n",
    "    # Pawn influences (including en passant)\n",
    "    white_pawn = board_tensor[0]\n",
    "    black_pawn = board_tensor[6]\n",
    "    influence_channels[0, :-1, 1:] += white_pawn[1:, :-1]  # Diagonal right\n",
    "    influence_channels[0, :-1, :-1] += white_pawn[1:, 1:]  # Diagonal left\n",
    "    influence_channels[6, 1:, 1:] += black_pawn[:-1, :-1]  # Diagonal right\n",
    "    influence_channels[6, 1:, :-1] += black_pawn[:-1, 1:]  # Diagonal left\n",
    "    \n",
    "    # En passant\n",
    "    if board_tensor[-1, 0, 0] == 1:  # White to move\n",
    "        ep_file = (board_tensor[12] == 0).float().sum(dim=0).argmax()\n",
    "        if ep_file > 0:\n",
    "            influence_channels[0, 2, ep_file-1] = 1\n",
    "        if ep_file < 7:\n",
    "            influence_channels[0, 2, ep_file+1] = 1\n",
    "    else:\n",
    "        ep_file = (board_tensor[12] == 0).float().sum(dim=0).argmax()\n",
    "        if ep_file > 0:\n",
    "            influence_channels[6, 5, ep_file-1] = 1\n",
    "        if ep_file < 7:\n",
    "            influence_channels[6, 5, ep_file+1] = 1\n",
    "    \n",
    "    # Knight influences\n",
    "    knight_kernel = torch.tensor([\n",
    "        [0,1,0,1,0],\n",
    "        [1,0,0,0,1],\n",
    "        [0,0,0,0,0],\n",
    "        [1,0,0,0,1],\n",
    "        [0,1,0,1,0]\n",
    "    ], dtype=torch.float32)\n",
    "    influence_channels[1] = torch.nn.functional.conv2d(board_tensor[1].unsqueeze(0).unsqueeze(0), knight_kernel.unsqueeze(0).unsqueeze(0), padding=2)[0, 0]\n",
    "    influence_channels[7] = torch.nn.functional.conv2d(board_tensor[7].unsqueeze(0).unsqueeze(0), knight_kernel.unsqueeze(0).unsqueeze(0), padding=2)[0, 0]\n",
    "    \n",
    "    # Sliding piece influences (Bishop, Rook, Queen)\n",
    "    for i, directions in enumerate([(1,1), (1,0), (1,1)]):  # Bishop, Rook, Queen\n",
    "        white_influence = torch.zeros(8, 8, dtype=torch.float32)\n",
    "        black_influence = torch.zeros(8, 8, dtype=torch.float32)\n",
    "        for dx, dy in [directions, (-directions[0], directions[1]), (directions[0], -directions[1]), (-directions[0], -directions[1])]:\n",
    "            ray = torch.zeros(8, 8, dtype=torch.float32)\n",
    "            x, y = 3, 3\n",
    "            while 0 <= x < 8 and 0 <= y < 8:\n",
    "                ray[x, y] = 1\n",
    "                x, y = x + dx, y + dy\n",
    "            white_influence += torch.nn.functional.conv2d(board_tensor[i+2].unsqueeze(0).unsqueeze(0), ray.unsqueeze(0).unsqueeze(0), padding='same')[0, 0]\n",
    "            black_influence += torch.nn.functional.conv2d(board_tensor[i+8].unsqueeze(0).unsqueeze(0), ray.unsqueeze(0).unsqueeze(0), padding='same')[0, 0]\n",
    "        influence_channels[i+2] = white_influence\n",
    "        influence_channels[i+8] = black_influence\n",
    "    \n",
    "    # King influences\n",
    "    king_kernel = torch.tensor([\n",
    "        [1,1,1],\n",
    "        [1,0,1],\n",
    "        [1,1,1]\n",
    "    ], dtype=torch.float32)\n",
    "    influence_channels[5] = torch.nn.functional.conv2d(board_tensor[5].unsqueeze(0).unsqueeze(0), king_kernel.unsqueeze(0).unsqueeze(0), padding=1)[0, 0]\n",
    "    influence_channels[11] = torch.nn.functional.conv2d(board_tensor[11].unsqueeze(0).unsqueeze(0), king_kernel.unsqueeze(0).unsqueeze(0), padding=1)[0, 0]\n",
    "    \n",
    "    # Add channels for total influence\n",
    "    influence_channels[12] = influence_channels[:6].sum(dim=0)  # White total influence\n",
    "    influence_channels[13] = influence_channels[6:12].sum(dim=0)  # Black total influence\n",
    "    \n",
    "    return influence_channels\n",
    "\n",
    "def combine_influences(influence_channels):\n",
    "    white_influence = influence_channels[:6].sum(dim=0)\n",
    "    black_influence = influence_channels[6:12].sum(dim=0)\n",
    "    \n",
    "    # Calculate total influence and control\n",
    "    total_influence = white_influence + black_influence\n",
    "    control = torch.tanh(white_influence - black_influence)\n",
    "    \n",
    "    # Calculate tension (squares contested by both sides)\n",
    "    tension = torch.min(white_influence, black_influence)\n",
    "    \n",
    "    # Calculate mobility (number of legal moves for each piece)\n",
    "    white_mobility = influence_channels[:6].sum()\n",
    "    black_mobility = influence_channels[6:12].sum()\n",
    "    \n",
    "    return {\n",
    "        'total_influence': total_influence,\n",
    "        'control': control,\n",
    "        'tension': tension,\n",
    "        'white_mobility': white_mobility,\n",
    "        'black_mobility': black_mobility\n",
    "    }\n",
    "\n",
    "def create_jepa_mask(influence_map, mask_ratio=0.25, min_region_size=2, max_region_size=4):\n",
    "    num_squares = influence_map.numel()\n",
    "    num_masked = int(num_squares * mask_ratio)\n",
    "    \n",
    "    # Create initial mask based on influence\n",
    "    _, indices = torch.topk(influence_map.flatten(), k=num_masked)\n",
    "    mask = torch.ones_like(influence_map, dtype=torch.bool)\n",
    "    mask.view(-1)[indices] = False\n",
    "    \n",
    "    # Expand mask regions\n",
    "    for _ in range(max_region_size - 1):\n",
    "        expanded_mask = torch.nn.functional.max_pool2d(\n",
    "            (~mask).float().unsqueeze(0).unsqueeze(0),\n",
    "            kernel_size=3, stride=1, padding=1\n",
    "        ).squeeze(0).squeeze(0).bool()\n",
    "        mask = ~expanded_mask\n",
    "        \n",
    "        if (~mask).sum() >= num_masked * max_region_size / min_region_size:\n",
    "            break\n",
    "    \n",
    "    # Trim excess masked squares\n",
    "    excess = (~mask).sum() - num_masked\n",
    "    if excess > 0:\n",
    "        trim_indices = torch.randperm((~mask).sum())[:excess]\n",
    "        mask[~mask] |= torch.zeros((~mask).sum(), dtype=torch.bool).scatter_(0, trim_indices, True)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def board_to_image(board):\n",
    "    svg = chess.svg.board(board=board, size=400)\n",
    "    png = svg2png(bytestring=svg)\n",
    "    return Image.open(io.BytesIO(png))\n",
    "\n",
    "def plot_board_with_overlay(ax, board_image, overlay_data, title, cmap='coolwarm'):\n",
    "    ax.imshow(board_image)\n",
    "    overlay = ax.imshow(overlay_data, cmap=cmap, alpha=0.6, vmin=-1, vmax=1)\n",
    "    ax.set_title(title)\n",
    "    ax.axis('off')\n",
    "    return overlay\n",
    "\n",
    "# # Set up the chess game\n",
    "# board = chess.Board()\n",
    "# moves = [\n",
    "#     \"d4\", \"Nf6\", \"c4\", \"e6\", \"Nc3\", \"Bb4\", \"e3\", \"O-O\", \"Bd3\", \"d5\", \"Nf3\", \"c5\", \"O-O\", \"cxd4\", \"exd4\", \"dxc4\",\n",
    "#     \"Bxc4\", \"b6\", \"Bg5\", \"Bb7\", \"Re1\", \"Nbd7\", \"Rc1\", \"Rc8\", \"Qb3\", \"Be7\", \"Bxf6\", \"Nxf6\", \"Bxe6\", \"fxe6\",\n",
    "#     \"Qxe6+\", \"Kh8\", \"Qxe7\", \"Bxf3\", \"gxf3\", \"Qxd4\", \"Nb5\", \"Qxb2\", \"Rxc8\", \"Rxc8\", \"Nd6\", \"Rb8\", \"Nf7+\", \"Kg8\",\n",
    "#     \"Qe6\", \"Rf8\", \"Nd8+\", \"Kh8\", \"Qe7\"\n",
    "# ]\n",
    "\n",
    "# for move in moves:\n",
    "#     board.push_san(move)\n",
    "\n",
    "# # Create board tensor and influence channels\n",
    "# board_tensor = board_to_tensor(board)\n",
    "# influence_channels = create_influence_channels(board_tensor)\n",
    "\n",
    "# # Combine influences\n",
    "# total_influence, control = combine_influences(influence_channels)\n",
    "\n",
    "# # Create JEPA-like mask\n",
    "# jepa_mask = create_jepa_mask(total_influence)\n",
    "\n",
    "# # Visualize the results\n",
    "# fig, axs = plt.subplots(1, 4, figsize=(25, 6))\n",
    "\n",
    "# board_image = np.array(board_to_image(board))\n",
    "\n",
    "# axs[0].imshow(board_image)\n",
    "# axs[0].set_title(\"Chess Board\")\n",
    "# axs[0].axis('off')\n",
    "\n",
    "# influence_overlay = plot_board_with_overlay(axs[1], board_image, total_influence.numpy(), \"Total Influence\", cmap='viridis')\n",
    "# control_overlay = plot_board_with_overlay(axs[2], board_image, control.numpy(), \"Board Control\")\n",
    "# mask_overlay = plot_board_with_overlay(axs[3], board_image, ~jepa_mask.numpy(), \"JEPA-like Mask\", cmap='binary')\n",
    "\n",
    "# plt.colorbar(influence_overlay, ax=axs[1], fraction=0.046, pad=0.04)\n",
    "# plt.colorbar(control_overlay, ax=axs[2], fraction=0.046, pad=0.04)\n",
    "# plt.colorbar(mask_overlay, ax=axs[3], fraction=0.046, pad=0.04)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# print(\"Total Influence:\")\n",
    "# print(total_influence.numpy())\n",
    "# print(\"\\nBoard Control (positive for white, negative for black):\")\n",
    "# print(control.numpy())\n",
    "# print(\"\\nJEPA-like mask (True = masked, False = visible):\")\n",
    "# print(jepa_mask.numpy())\n",
    "\n",
    "# def analyze_game_sequence(moves):\n",
    "#     board = chess.Board()\n",
    "#     influence_history = []\n",
    "#     control_history = []\n",
    "\n",
    "#     for move in moves:\n",
    "#         board.push_san(move)\n",
    "#         board_tensor = board_to_tensor(board)\n",
    "#         influence_channels = create_influence_channels(board_tensor)\n",
    "#         total_influence, control = combine_influences(influence_channels)\n",
    "#         influence_history.append(total_influence.numpy())\n",
    "#         control_history.append(control.numpy())\n",
    "\n",
    "#     return influence_history, control_history\n",
    "\n",
    "# def plot_game_progression(influence_history, control_history, moves, num_positions=8):\n",
    "#     num_moves = len(influence_history)\n",
    "#     positions_to_show = np.linspace(0, num_moves - 1, num_positions, dtype=int)\n",
    "\n",
    "#     fig, axs = plt.subplots(2, num_positions, figsize=(4 * num_positions, 8))\n",
    "\n",
    "#     for i, move_index in enumerate(positions_to_show):\n",
    "#         influence = influence_history[move_index]\n",
    "#         control = control_history[move_index]\n",
    "\n",
    "#         im1 = axs[0, i].imshow(influence, cmap='viridis')\n",
    "#         axs[0, i].set_title(f\"Influence (Move {move_index + 1})\\n{moves[move_index]}\")\n",
    "#         axs[0, i].axis('off')\n",
    "#         plt.colorbar(im1, ax=axs[0, i], fraction=0.046, pad=0.04)\n",
    "\n",
    "#         im2 = axs[1, i].imshow(control, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "#         axs[1, i].set_title(f\"Control (Move {move_index + 1})\\n{moves[move_index]}\")\n",
    "#         axs[1, i].axis('off')\n",
    "#         plt.colorbar(im2, ax=axs[1, i], fraction=0.046, pad=0.04)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "def analyze_game_sequence(moves: List[str]) -> Dict[str, List[torch.Tensor]]:\n",
    "    board = chess.Board()\n",
    "    history = {\n",
    "        'influence': [],\n",
    "        'control': [],\n",
    "        'tension': [],\n",
    "        'white_mobility': [],\n",
    "        'black_mobility': [],\n",
    "        'board_tensors': [],\n",
    "        'influence_channels': []\n",
    "    }\n",
    "    \n",
    "    for move in moves:\n",
    "        board.push_san(move)\n",
    "        board_tensor = board_to_tensor(board)\n",
    "        influence_channels = create_influence_channels(board_tensor)\n",
    "        metrics = combine_influences(influence_channels)\n",
    "        \n",
    "        history['board_tensors'].append(board_tensor)\n",
    "        history['influence_channels'].append(influence_channels)\n",
    "        history['influence'].append(metrics['total_influence'])\n",
    "        history['control'].append(metrics['control'])\n",
    "        history['tension'].append(metrics['tension'])\n",
    "        history['white_mobility'].append(metrics['white_mobility'])\n",
    "        history['black_mobility'].append(metrics['black_mobility'])\n",
    "    \n",
    "    return history\n",
    "\n",
    "def plot_game_progression(history: Dict[str, List[torch.Tensor]], moves: List[str], num_positions: int = 8):\n",
    "    num_moves = len(history['influence'])\n",
    "    positions_to_show = np.linspace(0, num_moves - 1, num_positions, dtype=int)\n",
    "    \n",
    "    fig, axs = plt.subplots(3, num_positions, figsize=(4 * num_positions, 12))\n",
    "    \n",
    "    for i, move_index in enumerate(positions_to_show):\n",
    "        influence = history['influence'][move_index].numpy()\n",
    "        control = history['control'][move_index].numpy()\n",
    "        tension = history['tension'][move_index].numpy()\n",
    "        \n",
    "        im1 = axs[0, i].imshow(influence, cmap='viridis')\n",
    "        axs[0, i].set_title(f\"Influence (Move {move_index + 1})\\n{moves[move_index]}\")\n",
    "        axs[0, i].axis('off')\n",
    "        plt.colorbar(im1, ax=axs[0, i], fraction=0.046, pad=0.04)\n",
    "        \n",
    "        im2 = axs[1, i].imshow(control, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        axs[1, i].set_title(f\"Control (Move {move_index + 1})\\n{moves[move_index]}\")\n",
    "        axs[1, i].axis('off')\n",
    "        plt.colorbar(im2, ax=axs[1, i], fraction=0.046, pad=0.04)\n",
    "        \n",
    "        im3 = axs[2, i].imshow(tension, cmap='hot', vmin=0, vmax=2)\n",
    "        axs[2, i].set_title(f\"Tension (Move {move_index + 1})\\n{moves[move_index]}\")\n",
    "        axs[2, i].axis('off')\n",
    "        plt.colorbar(im3, ax=axs[2, i], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot mobility\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(history['white_mobility'], label='White Mobility')\n",
    "    plt.plot(history['black_mobility'], label='Black Mobility')\n",
    "    plt.xlabel('Move Number')\n",
    "    plt.ylabel('Mobility')\n",
    "    plt.title('Mobility Throughout the Game')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "def analyze_and_plot_game(moves: List[str], num_positions: int = 8):\n",
    "    history = analyze_game_sequence(moves)\n",
    "    plot_game_progression(history, moves, num_positions)\n",
    "    return history\n",
    "\n",
    "def find_critical_moments(history: Dict[str, List[torch.Tensor]], threshold: float = 0.5) -> List[int]:\n",
    "    \"\"\"\n",
    "    Identify critical moments in the game based on significant changes in board control.\n",
    "    \n",
    "    Args:\n",
    "    history (Dict[str, List[torch.Tensor]]): Game history containing control tensors.\n",
    "    threshold (float): The minimum change in control to be considered critical.\n",
    "    \n",
    "    Returns:\n",
    "    List[int]: Indices of critical moments.\n",
    "    \"\"\"\n",
    "    control_changes = [torch.abs(history['control'][i+1] - history['control'][i]).max().item() \n",
    "                       for i in range(len(history['control']) - 1)]\n",
    "    critical_moments = [i for i, change in enumerate(control_changes) if change > threshold]\n",
    "    return critical_moments\n",
    "\n",
    "def plot_jepa_masks(history: Dict[str, List[torch.Tensor]], moves: List[str], num_positions: int = 8):\n",
    "    num_moves = len(history['influence'])\n",
    "    positions_to_show = np.linspace(0, num_moves - 1, num_positions, dtype=int)\n",
    "    \n",
    "    fig, axs = plt.subplots(2, num_positions, figsize=(4 * num_positions, 8))\n",
    "    \n",
    "    for i, move_index in enumerate(positions_to_show):\n",
    "        board_tensor = history['board_tensors'][move_index]\n",
    "        influence_channels = history['influence_channels'][move_index]\n",
    "        \n",
    "        # Create JEPA mask\n",
    "        combined_tensor = torch.cat([board_tensor, influence_channels], dim=0)\n",
    "        mask = create_jepa_mask(combined_tensor.sum(dim=0))\n",
    "        \n",
    "        # Plot board state\n",
    "        axs[0, i].imshow(board_tensor.sum(dim=0).numpy(), cmap='viridis')\n",
    "        axs[0, i].set_title(f\"Board State (Move {move_index + 1})\\n{moves[move_index]}\")\n",
    "        axs[0, i].axis('off')\n",
    "        \n",
    "        # Plot JEPA mask\n",
    "        mask_img = axs[1, i].imshow(mask.float().numpy(), cmap='gray_r')\n",
    "        axs[1, i].set_title(f\"JEPA Mask (Move {move_index + 1})\")\n",
    "        axs[1, i].axis('off')\n",
    "        plt.colorbar(mask_img, ax=axs[1, i], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_alphazero_immortal_with_jepa():\n",
    "    # Analyze the game sequence\n",
    "    game_history = analyze_game_sequence(moves)\n",
    "    \n",
    "    # Plot the game progression\n",
    "    plot_game_progression(game_history, moves)\n",
    "    \n",
    "    # Plot JEPA masks\n",
    "    plot_jepa_masks(game_history, moves)\n",
    "    \n",
    "    # Print final metrics\n",
    "    print(\"Final Total Influence:\")\n",
    "    print(game_history['influence'][-1].numpy())\n",
    "    print(\"\\nFinal Board Control (positive for white, negative for black):\")\n",
    "    print(game_history['control'][-1].numpy())\n",
    "    print(\"\\nFinal Tension:\")\n",
    "    print(game_history['tension'][-1].numpy())\n",
    "    print(\"\\nFinal White Mobility:\", game_history['white_mobility'][-1].item())\n",
    "    print(\"\\nFinal Black Mobility:\", game_history['black_mobility'][-1].item())\n",
    "    \n",
    "    # Plot mobility throughout the game\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(game_history['white_mobility'], label='White Mobility')\n",
    "    plt.plot(game_history['black_mobility'], label='Black Mobility')\n",
    "    plt.xlabel('Move Number')\n",
    "    plt.ylabel('Mobility')\n",
    "    plt.title('Mobility Throughout AlphaZero\\'s Immortal Game')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    # Analyze critical moments\n",
    "    critical_moments = find_critical_moments(game_history)\n",
    "    print(\"\\nCritical Moments (move numbers):\")\n",
    "    print([moment + 1 for moment in critical_moments])\n",
    "    \n",
    "    # Plot control and JEPA masks at critical moments\n",
    "    num_critical = min(5, len(critical_moments))\n",
    "    fig, axs = plt.subplots(2, num_critical, figsize=(4 * num_critical, 8))\n",
    "    for i, moment in enumerate(critical_moments[:num_critical]):\n",
    "        # Plot control\n",
    "        im1 = axs[0, i].imshow(game_history['control'][moment].numpy(), cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        axs[0, i].set_title(f\"Control (Move {moment + 1})\\n{moves[moment]}\")\n",
    "        axs[0, i].axis('off')\n",
    "        plt.colorbar(im1, ax=axs[0, i], fraction=0.046, pad=0.04)\n",
    "        \n",
    "        # Plot JEPA mask\n",
    "        combined_tensor = torch.cat([game_history['board_tensors'][moment], game_history['influence_channels'][moment]], dim=0)\n",
    "        mask = create_jepa_mask(combined_tensor.sum(dim=0))\n",
    "        im2 = axs[1, i].imshow(mask.float().numpy(), cmap='gray_r')\n",
    "        axs[1, i].set_title(f\"JEPA Mask (Move {moment + 1})\")\n",
    "        axs[1, i].axis('off')\n",
    "        plt.colorbar(im2, ax=axs[1, i], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return game_history\n",
    "\n",
    "# vladimir borisovich's win\n",
    "moves = [\n",
    "    \"d4\", \"Nf6\", \"c4\", \"e6\", \"Nc3\", \"Bb4\", \"e3\", \"O-O\", \"Bd3\", \"d5\", \"Nf3\", \"c5\", \"O-O\", \"cxd4\", \"exd4\", \"dxc4\",\n",
    "    \"Bxc4\", \"b6\", \"Bg5\", \"Bb7\", \"Re1\", \"Nbd7\", \"Rc1\", \"Rc8\", \"Qb3\", \"Be7\", \"Bxf6\", \"Nxf6\", \"Bxe6\", \"fxe6\",\n",
    "    \"Qxe6+\", \"Kh8\", \"Qxe7\", \"Bxf3\", \"gxf3\", \"Qxd4\", \"Nb5\", \"Qxb2\", \"Rxc8\", \"Rxc8\", \"Nd6\", \"Rb8\", \"Nf7+\", \"Kg8\",\n",
    "    \"Qe6\", \"Rf8\", \"Nd8+\", \"Kh8\", \"Qe7\"\n",
    "]\n",
    "\n",
    "# # Analyze the game sequence\n",
    "# influence_history, control_history = analyze_game_sequence(moves)\n",
    "\n",
    "# # Plot the game progression\n",
    "# plot_game_progression(influence_history, control_history)\n",
    "\n",
    "# # Print final influence and control\n",
    "# print(\"Final Total Influence:\")\n",
    "# print(influence_history[-1])\n",
    "# print(\"\\nFinal Board Control (positive for white, negative for black):\")\n",
    "# print(control_history[-1])\n",
    "\n",
    "# # AlphaZero's Immortal game\n",
    "# moves = [\n",
    "#     \"Nf3\", \"Nf6\", \"c4\", \"e6\", \"Nc3\", \"Bb4\", \"Qc2\", \"O-O\", \"a3\", \"Bxc3\", \"Qxc3\", \"a5\", \"b4\", \"d6\", \"e3\", \"Ne4\", \n",
    "#     \"Qc2\", \"Ng5\", \"b5\", \"Nxf3+\", \"gxf3\", \"Qf6\", \"d4\", \"Qxf3\", \"Rg1\", \"Nd7\", \"Be2\", \"Qf6\", \"Bb2\", \"Qh4\", \"Rg4\", \n",
    "#     \"Qxh2\", \"Rg3\", \"f5\", \"O-O-O\", \"Rf7\", \"Bf3\", \"Qh4\", \"Rh1\", \"Qf6\", \"Kb1\", \"g6\", \"Rgg1\", \"a4\", \"Ka1\", \"Rg7\", \n",
    "#     \"e4\", \"f4\", \"c5\", \"Qe7\", \"Rc1\", \"Nf6\", \"e5\", \"dxe5\", \"Rhe1\", \"e4\", \"Bxe4\", \"Qf8\", \"d5\", \"exd5\", \"Bd3\", \n",
    "#     \"Bg4\", \"f3\", \"Bd7\", \"Qc3\", \"Nh5\", \"Re5\", \"c6\", \"Rce1\", \"Nf6\", \"Qd4\", \"cxb5\", \"Bb1\", \"Bc6\", \"Re6\", \"Rf7\", \n",
    "#     \"Rg1\", \"Qg7\", \"Qxf4\", \"Re8\", \"Rd6\", \"Nd7\", \"Qc1\", \"Rf6\", \"f4\", \"Qe7\", \"Rxf6\", \"Nxf6\", \"f5\", \"Qe3\", \"fxg6\", \n",
    "#     \"Qxc1\", \"gxh7+\", \"Kf7\", \"Rxc1\", \"Nxh7\", \"Bxh7\", \"Re3\", \"Rd1\", \"Ke8\", \"Ka2\", \"Bd7\", \"Bd4\", \"Rh3\", \"Bc2\", \n",
    "#     \"Be6\", \"Re1\", \"Kd7\", \"Kb2\", \"Rf3\", \"Re5\", \"Rg3\", \"Re3\", \"Rg2\", \"Kc3\", \"Rg4\", \"Rf3\", \"Ke8\", \"Rf2\", \"Rg3+\", \n",
    "#     \"Kb4\", \"Rg4\", \"Rd2\", \"Bd7\", \"Ka5\", \"Rf4\", \"Be5\", \"Rf3\", \"Rd3\", \"Rf2\", \"Bd1\", \"Bc6\", \"Kb6\"\n",
    "# ]\n",
    "\n",
    "# # Analyze the game sequence\n",
    "# influence_history, control_history = analyze_game_sequence(moves)\n",
    "\n",
    "# # Plot the game progression\n",
    "# plot_game_progression(influence_history, control_history, moves)\n",
    "\n",
    "# # Print final influence and control\n",
    "# print(\"Final Total Influence:\")\n",
    "# print(influence_history[-1])\n",
    "# print(\"\\nFinal Board Control (positive for white, negative for black):\")\n",
    "# print(control_history[-1])\n",
    "\n",
    "# AlphaZero's Immortal game moves\n",
    "moves = [\n",
    "    \"Nf3\", \"Nf6\", \"c4\", \"e6\", \"Nc3\", \"Bb4\", \"Qc2\", \"O-O\", \"a3\", \"Bxc3\", \"Qxc3\", \"a5\", \"b4\", \"d6\", \"e3\", \"Ne4\",\n",
    "    \"Qc2\", \"Ng5\", \"b5\", \"Nxf3+\", \"gxf3\", \"Qf6\", \"d4\", \"Qxf3\", \"Rg1\", \"Nd7\", \"Be2\", \"Qf6\", \"Bb2\", \"Qh4\", \"Rg4\",\n",
    "    \"Qxh2\", \"Rg3\", \"f5\", \"O-O-O\", \"Rf7\", \"Bf3\", \"Qh4\", \"Rh1\", \"Qf6\", \"Kb1\", \"g6\", \"Rgg1\", \"a4\", \"Ka1\", \"Rg7\",\n",
    "    \"e4\", \"f4\", \"c5\", \"Qe7\", \"Rc1\", \"Nf6\", \"e5\", \"dxe5\", \"Rhe1\", \"e4\", \"Bxe4\", \"Qf8\", \"d5\", \"exd5\", \"Bd3\",\n",
    "    \"Bg4\", \"f3\", \"Bd7\", \"Qc3\", \"Nh5\", \"Re5\", \"c6\", \"Rce1\", \"Nf6\", \"Qd4\", \"cxb5\", \"Bb1\", \"Bc6\", \"Re6\", \"Rf7\",\n",
    "    \"Rg1\", \"Qg7\", \"Qxf4\", \"Re8\", \"Rd6\", \"Nd7\", \"Qc1\", \"Rf6\", \"f4\", \"Qe7\", \"Rxf6\", \"Nxf6\", \"f5\", \"Qe3\", \"fxg6\",\n",
    "    \"Qxc1\", \"gxh7+\", \"Kf7\", \"Rxc1\", \"Nxh7\", \"Bxh7\", \"Re3\", \"Rd1\", \"Ke8\", \"Ka2\", \"Bd7\", \"Bd4\", \"Rh3\", \"Bc2\",\n",
    "    \"Be6\", \"Re1\", \"Kd7\", \"Kb2\", \"Rf3\", \"Re5\", \"Rg3\", \"Re3\", \"Rg2\", \"Kc3\", \"Rg4\", \"Rf3\", \"Ke8\", \"Rf2\", \"Rg3+\",\n",
    "    \"Kb4\", \"Rg4\", \"Rd2\", \"Bd7\", \"Ka5\", \"Rf4\", \"Be5\", \"Rf3\", \"Rd3\", \"Rf2\", \"Bd1\", \"Bc6\", \"Kb6\"\n",
    "]\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.special import kl_div\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def update_ema(current_ema: torch.Tensor, new_value: torch.Tensor, alpha: float = 0.1) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Update the exponential moving average.\n",
    "    \n",
    "    Args:\n",
    "    current_ema (torch.Tensor): Current EMA tensor\n",
    "    new_value (torch.Tensor): New tensor to incorporate\n",
    "    alpha (float): EMA weight (0 < alpha <= 1)\n",
    "    \n",
    "    Returns:\n",
    "    torch.Tensor: Updated EMA\n",
    "    \"\"\"\n",
    "    return alpha * new_value + (1 - alpha) * current_ema\n",
    "\n",
    "def calculate_kl_divergence(p: np.ndarray, q: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate KL divergence between two distributions.\n",
    "    \n",
    "    Args:\n",
    "    p (np.ndarray): First distribution\n",
    "    q (np.ndarray): Second distribution\n",
    "    \n",
    "    Returns:\n",
    "    float: KL divergence\n",
    "    \"\"\"\n",
    "    return np.sum(kl_div(p, q))\n",
    "\n",
    "def calculate_js_divergence(p: np.ndarray, q: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate Jensen-Shannon divergence between two distributions.\n",
    "    \n",
    "    Args:\n",
    "    p (np.ndarray): First distribution\n",
    "    q (np.ndarray): Second distribution\n",
    "    \n",
    "    Returns:\n",
    "    float: JS divergence\n",
    "    \"\"\"\n",
    "    return jensenshannon(p, q, base=2)**2\n",
    "\n",
    "def analyze_game_sequence_with_ema_divergence(moves: List[str]) -> Dict[str, List[float]]:\n",
    "    board = chess.Board()\n",
    "    history = {\n",
    "        'kl_divergence': [],\n",
    "        'js_divergence': [],\n",
    "        'total_influence': []\n",
    "    }\n",
    "    \n",
    "    ema_influence = None\n",
    "    \n",
    "    for move in moves:\n",
    "        board.push_san(move)\n",
    "        board_tensor = board_to_tensor(board)\n",
    "        influence_channels = create_influence_channels(board_tensor)\n",
    "        \n",
    "        # Flatten and normalize influence channels\n",
    "        flat_influence = influence_channels.view(-1)\n",
    "        norm_influence = flat_influence / (flat_influence.sum() + 1e-10)\n",
    "        \n",
    "        if ema_influence is None:\n",
    "            ema_influence = norm_influence\n",
    "        else:\n",
    "            # Calculate divergences\n",
    "            kl_div = calculate_kl_divergence(ema_influence.numpy(), norm_influence.numpy())\n",
    "            js_div = calculate_js_divergence(ema_influence.numpy(), norm_influence.numpy())\n",
    "            \n",
    "            history['kl_divergence'].append(kl_div)\n",
    "            history['js_divergence'].append(js_div)\n",
    "            \n",
    "            # Update EMA\n",
    "            ema_influence = update_ema(ema_influence, norm_influence)\n",
    "        \n",
    "        history['total_influence'].append(flat_influence.sum().item())\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Analyze the game with EMA and divergence\n",
    "ema_divergence_history = analyze_game_sequence_with_ema_divergence(moves)\n",
    "\n",
    "# Plot KL and JS divergences\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ema_divergence_history['kl_divergence'], label='KL Divergence')\n",
    "plt.plot(ema_divergence_history['js_divergence'], label='JS Divergence')\n",
    "plt.xlabel('Move')\n",
    "plt.ylabel('Divergence')\n",
    "plt.title('KL and JS Divergences of Influence EMA throughout the game')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Plot total influence\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(ema_divergence_history['total_influence'], label='Total Influence')\n",
    "plt.xlabel('Move')\n",
    "plt.ylabel('Total Influence')\n",
    "plt.title('Total Influence throughout the game')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print some statistics\n",
    "print(\"KL Divergence range:\", min(ema_divergence_history['kl_divergence']), \"to\", max(ema_divergence_history['kl_divergence']))\n",
    "print(\"JS Divergence range:\", min(ema_divergence_history['js_divergence']), \"to\", max(ema_divergence_history['js_divergence']))\n",
    "print(\"Total Influence range:\", min(ema_divergence_history['total_influence']), \"to\", max(ema_divergence_history['total_influence']))\n",
    "\n",
    "# def analyze_alphazero_immortal():\n",
    "#     # Analyze the game sequence\n",
    "#     game_history = analyze_game_sequence(moves)\n",
    "    \n",
    "#     # Plot the game progression\n",
    "#     plot_game_progression(game_history, moves)\n",
    "    \n",
    "#     # Print final metrics\n",
    "#     print(\"Final Total Influence:\")\n",
    "#     print(game_history['influence'][-1].numpy())\n",
    "#     print(\"\\nFinal Board Control (positive for white, negative for black):\")\n",
    "#     print(game_history['control'][-1].numpy())\n",
    "#     print(\"\\nFinal Tension:\")\n",
    "#     print(game_history['tension'][-1].numpy())\n",
    "#     print(\"\\nFinal White Mobility:\", game_history['white_mobility'][-1].item())\n",
    "#     print(\"Final Black Mobility:\", game_history['black_mobility'][-1].item())\n",
    "    \n",
    "#     # Plot mobility throughout the game\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.plot(game_history['white_mobility'], label='White Mobility')\n",
    "#     plt.plot(game_history['black_mobility'], label='Black Mobility')\n",
    "#     plt.xlabel('Move Number')\n",
    "#     plt.ylabel('Mobility')\n",
    "#     plt.title('Mobility Throughout AlphaZero\\'s Immortal Game')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "    \n",
    "#     return game_history\n",
    "\n",
    "# Run the analysis\n",
    "alphazero_immortal_history = analyze_alphazero_immortal_with_jepa()\n",
    "\n",
    "# from scipy.stats import entropy\n",
    "# import torch.nn.functional as F\n",
    "# import math\n",
    "\n",
    "# def calculate_influence_entropy(influence_channels: torch.Tensor) -> torch.Tensor:\n",
    "#     \"\"\"\n",
    "#     Calculate entropy based on the influence maps from our tensor representation.\n",
    "    \n",
    "#     Args:\n",
    "#     influence_channels (torch.Tensor): The influence channels tensor\n",
    "    \n",
    "#     Returns:\n",
    "#     torch.Tensor: Entropy scalar\n",
    "#     \"\"\"\n",
    "#     # Separate white and black influence\n",
    "#     white_influence = influence_channels[:6].sum(dim=0)\n",
    "#     black_influence = influence_channels[6:12].sum(dim=0)\n",
    "    \n",
    "#     # Normalize influences\n",
    "#     total_influence = white_influence + black_influence\n",
    "#     white_prob = white_influence / (total_influence + 1e-10)\n",
    "#     black_prob = black_influence / (total_influence + 1e-10)\n",
    "    \n",
    "#     # Calculate entropy for each square\n",
    "#     square_entropy = -(white_prob * torch.log2(white_prob + 1e-10) + \n",
    "#                        black_prob * torch.log2(black_prob + 1e-10))\n",
    "    \n",
    "#     # Weight entropy by total influence\n",
    "#     weighted_entropy = square_entropy * total_influence\n",
    "    \n",
    "#     # Sum entropy across the board\n",
    "#     total_entropy = weighted_entropy.sum()\n",
    "    \n",
    "#     return total_entropy\n",
    "\n",
    "# def analyze_game_sequence_with_influence_entropy(moves: List[str]) -> Dict[str, List[torch.Tensor]]:\n",
    "#     board = chess.Board()\n",
    "#     history = {\n",
    "#         'entropy': [],\n",
    "#         'total_influence': []\n",
    "#     }\n",
    "    \n",
    "#     for move in moves:\n",
    "#         board.push_san(move)\n",
    "#         board_tensor = board_to_tensor(board)\n",
    "#         influence_channels = create_influence_channels(board_tensor)\n",
    "        \n",
    "#         entropy = calculate_influence_entropy(influence_channels)\n",
    "#         total_influence = influence_channels.sum()\n",
    "        \n",
    "#         history['entropy'].append(entropy)\n",
    "#         history['total_influence'].append(total_influence)\n",
    "    \n",
    "#     return history\n",
    "\n",
    "# # Analyze the game with influence-based entropy\n",
    "# influence_entropy_history = analyze_game_sequence_with_influence_entropy(moves)\n",
    "\n",
    "# # Plot influence-based entropy\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot([e.item() for e in influence_entropy_history['entropy']], label='Influence Entropy')\n",
    "# plt.plot([t.item() for t in influence_entropy_history['total_influence']], label='Total Influence')\n",
    "# plt.xlabel('Move')\n",
    "# plt.ylabel('Value')\n",
    "# plt.title('Chess Influence Entropy and Total Influence throughout the game')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()\n",
    "\n",
    "# # Print some statistics\n",
    "# print(\"Entropy range:\", min(influence_entropy_history['entropy']).item(), \"to\", max(influence_entropy_history['entropy']).item())\n",
    "# print(\"Total influence range:\", min(influence_entropy_history['total_influence']).item(), \"to\", max(influence_entropy_history['total_influence']).item())\n",
    "\n",
    "# def analyze_game_sequence(moves):\n",
    "#     board = chess.Board()\n",
    "#     influence_history = []\n",
    "#     control_history = []\n",
    "#     influence_shifts = []\n",
    "#     control_shifts = []\n",
    "\n",
    "#     for move in moves:\n",
    "#         board.push_san(move)\n",
    "#         board_tensor = board_to_tensor(board)\n",
    "#         influence_channels = create_influence_channels(board_tensor)\n",
    "#         total_influence, control = combine_influences(influence_channels)\n",
    "        \n",
    "#         influence_history.append(total_influence.numpy())\n",
    "#         control_history.append(control.numpy())\n",
    "        \n",
    "#         if len(influence_history) > 1:\n",
    "#             influence_shift = np.sum(np.abs(influence_history[-1] - influence_history[-2]))\n",
    "#             control_shift = np.sum(np.abs(control_history[-1] - control_history[-2]))\n",
    "#             influence_shifts.append(influence_shift)\n",
    "#             control_shifts.append(control_shift)\n",
    "\n",
    "#     return influence_history, control_history, influence_shifts, control_shifts\n",
    "\n",
    "# def plot_game_stats(moves, influence_shifts, control_shifts):\n",
    "#     plt.figure(figsize=(15, 10))\n",
    "    \n",
    "#     plt.subplot(2, 1, 1)\n",
    "#     plt.plot(influence_shifts, label='Influence Shift')\n",
    "#     plt.title('Influence Shifts Throughout the Game')\n",
    "#     plt.xlabel('Move Number')\n",
    "#     plt.ylabel('Total Absolute Change')\n",
    "#     plt.legend()\n",
    "    \n",
    "#     plt.subplot(2, 1, 2)\n",
    "#     plt.plot(control_shifts, label='Control Shift', color='orange')\n",
    "#     plt.title('Control Shifts Throughout the Game')\n",
    "#     plt.xlabel('Move Number')\n",
    "#     plt.ylabel('Total Absolute Change')\n",
    "#     plt.legend()\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# def identify_key_moves(moves, influence_shifts, control_shifts, top_n=5):\n",
    "#     combined_shifts = np.array(influence_shifts) + np.array(control_shifts)\n",
    "#     top_indices = combined_shifts.argsort()[-top_n:][::-1]\n",
    "    \n",
    "#     print(f\"Top {top_n} Most Impactful Moves:\")\n",
    "#     for i, idx in enumerate(top_indices, 1):\n",
    "#         print(f\"{i}. Move {idx+1}: {moves[idx]} (Influence Shift: {influence_shifts[idx]:.2f}, Control Shift: {control_shifts[idx]:.2f})\")\n",
    "\n",
    "# def calculate_game_stats(influence_history, control_history):\n",
    "#     influence_array = np.array(influence_history)\n",
    "#     control_array = np.array(control_history)\n",
    "    \n",
    "#     avg_influence = np.mean(influence_array, axis=0)\n",
    "#     avg_control = np.mean(control_array, axis=0)\n",
    "    \n",
    "#     white_advantage = np.sum(control_array > 0, axis=1) / 64  # Percentage of squares controlled by white\n",
    "#     black_advantage = np.sum(control_array < 0, axis=1) / 64  # Percentage of squares controlled by black\n",
    "    \n",
    "#     print(\"\\nGame Statistics:\")\n",
    "#     print(f\"Average Total Influence:\\n{avg_influence}\")\n",
    "#     print(f\"\\nAverage Control (positive for white, negative for black):\\n{avg_control}\")\n",
    "#     print(f\"\\nWhite's average board control: {np.mean(white_advantage):.2%}\")\n",
    "#     print(f\"Black's average board control: {np.mean(black_advantage):.2%}\")\n",
    "#     print(f\"\\nLargest white advantage: {np.max(white_advantage):.2%} (Move {np.argmax(white_advantage)+1})\")\n",
    "#     print(f\"Largest black advantage: {np.max(black_advantage):.2%} (Move {np.argmax(black_advantage)+1})\")\n",
    "\n",
    "# # AlphaZero's Immortal game moves\n",
    "# moves = [\n",
    "#     \"Nf3\", \"Nf6\", \"c4\", \"e6\", \"Nc3\", \"Bb4\", \"Qc2\", \"O-O\", \"a3\", \"Bxc3\", \"Qxc3\", \"a5\", \"b4\", \"d6\", \"e3\", \"Ne4\", \n",
    "#     \"Qc2\", \"Ng5\", \"b5\", \"Nxf3+\", \"gxf3\", \"Qf6\", \"d4\", \"Qxf3\", \"Rg1\", \"Nd7\", \"Be2\", \"Qf6\", \"Bb2\", \"Qh4\", \"Rg4\", \n",
    "#     \"Qxh2\", \"Rg3\", \"f5\", \"O-O-O\", \"Rf7\", \"Bf3\", \"Qh4\", \"Rh1\", \"Qf6\", \"Kb1\", \"g6\", \"Rgg1\", \"a4\", \"Ka1\", \"Rg7\", \n",
    "#     \"e4\", \"f4\", \"c5\", \"Qe7\", \"Rc1\", \"Nf6\", \"e5\", \"dxe5\", \"Rhe1\", \"e4\", \"Bxe4\", \"Qf8\", \"d5\", \"exd5\", \"Bd3\", \n",
    "#     \"Bg4\", \"f3\", \"Bd7\", \"Qc3\", \"Nh5\", \"Re5\", \"c6\", \"Rce1\", \"Nf6\", \"Qd4\", \"cxb5\", \"Bb1\", \"Bc6\", \"Re6\", \"Rf7\", \n",
    "#     \"Rg1\", \"Qg7\", \"Qxf4\", \"Re8\", \"Rd6\", \"Nd7\", \"Qc1\", \"Rf6\", \"f4\", \"Qe7\", \"Rxf6\", \"Nxf6\", \"f5\", \"Qe3\", \"fxg6\", \n",
    "#     \"Qxc1\", \"gxh7+\", \"Kf7\", \"Rxc1\", \"Nxh7\", \"Bxh7\", \"Re3\", \"Rd1\", \"Ke8\", \"Ka2\", \"Bd7\", \"Bd4\", \"Rh3\", \"Bc2\", \n",
    "#     \"Be6\", \"Re1\", \"Kd7\", \"Kb2\", \"Rf3\", \"Re5\", \"Rg3\", \"Re3\", \"Rg2\", \"Kc3\", \"Rg4\", \"Rf3\", \"Ke8\", \"Rf2\", \"Rg3+\", \n",
    "#     \"Kb4\", \"Rg4\", \"Rd2\", \"Bd7\", \"Ka5\", \"Rf4\", \"Be5\", \"Rf3\", \"Rd3\", \"Rf2\", \"Bd1\", \"Bc6\", \"Kb6\"\n",
    "# ]\n",
    "\n",
    "# # Analyze the game sequence\n",
    "# influence_history, control_history, influence_shifts, control_shifts = analyze_game_sequence(moves)\n",
    "\n",
    "# # Plot game statistics\n",
    "# plot_game_stats(moves, influence_shifts, control_shifts)\n",
    "\n",
    "# # Identify key moves\n",
    "# identify_key_moves(moves, influence_shifts, control_shifts)\n",
    "\n",
    "# # Calculate and print game statistics\n",
    "# calculate_game_stats(influence_history, control_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import chess.engine\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "import json\n",
    "import torch\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "# Python backend\n",
    "\n",
    "def board_to_tensor(board):\n",
    "    piece_to_index = {'P': 0, 'N': 1, 'B': 2, 'R': 3, 'Q': 4, 'K': 5,\n",
    "                      'p': 6, 'n': 7, 'b': 8, 'r': 9, 'q': 10, 'k': 11}\n",
    "    tensor = torch.zeros(13, 8, 8, dtype=torch.float32)\n",
    "    for square, piece in board.piece_map().items():\n",
    "        rank, file = divmod(square, 8)\n",
    "        tensor[piece_to_index[piece.symbol()]][7-rank][file] = 1\n",
    "    \n",
    "    tensor[12] = 1 - tensor.sum(dim=0)\n",
    "    tensor = torch.cat([tensor, tensor[:6] + tensor[6:12], torch.full((1, 8, 8), float(board.turn))], dim=0)\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "def create_influence_channels(board_tensor):\n",
    "    influence_channels = torch.zeros(14, 8, 8, dtype=torch.float32)\n",
    "    \n",
    "    # Pawn influences\n",
    "    white_pawn, black_pawn = board_tensor[0], board_tensor[6]\n",
    "    influence_channels[0, :-1, 1:] += white_pawn[1:, :-1]\n",
    "    influence_channels[0, :-1, :-1] += white_pawn[1:, 1:]\n",
    "    influence_channels[6, 1:, 1:] += black_pawn[:-1, :-1]\n",
    "    influence_channels[6, 1:, :-1] += black_pawn[:-1, 1:]\n",
    "    \n",
    "    # Knight influences\n",
    "    knight_kernel = torch.tensor([[0,1,0,1,0],[1,0,0,0,1],[0,0,0,0,0],[1,0,0,0,1],[0,1,0,1,0]], dtype=torch.float32)\n",
    "    influence_channels[1] = torch.nn.functional.conv2d(board_tensor[1].unsqueeze(0).unsqueeze(0), knight_kernel.unsqueeze(0).unsqueeze(0), padding=2)[0, 0]\n",
    "    influence_channels[7] = torch.nn.functional.conv2d(board_tensor[7].unsqueeze(0).unsqueeze(0), knight_kernel.unsqueeze(0).unsqueeze(0), padding=2)[0, 0]\n",
    "    \n",
    "    # Sliding piece influences\n",
    "    for i, directions in enumerate([(1,1), (1,0), (1,1)]):\n",
    "        for dx, dy in [directions, (-directions[0], directions[1]), (directions[0], -directions[1]), (-directions[0], -directions[1])]:\n",
    "            ray = torch.zeros(8, 8, dtype=torch.float32)\n",
    "            x, y = 3, 3\n",
    "            while 0 <= x < 8 and 0 <= y < 8:\n",
    "                ray[x, y] = 1\n",
    "                x, y = x + dx, y + dy\n",
    "            influence_channels[i+2] += torch.nn.functional.conv2d(board_tensor[i+2].unsqueeze(0).unsqueeze(0), ray.unsqueeze(0).unsqueeze(0), padding='same')[0, 0]\n",
    "            influence_channels[i+8] += torch.nn.functional.conv2d(board_tensor[i+8].unsqueeze(0).unsqueeze(0), ray.unsqueeze(0).unsqueeze(0), padding='same')[0, 0]\n",
    "    \n",
    "    # King influences\n",
    "    king_kernel = torch.tensor([[1,1,1],[1,0,1],[1,1,1]], dtype=torch.float32)\n",
    "    influence_channels[5] = torch.nn.functional.conv2d(board_tensor[5].unsqueeze(0).unsqueeze(0), king_kernel.unsqueeze(0).unsqueeze(0), padding=1)[0, 0]\n",
    "    influence_channels[11] = torch.nn.functional.conv2d(board_tensor[11].unsqueeze(0).unsqueeze(0), king_kernel.unsqueeze(0).unsqueeze(0), padding=1)[0, 0]\n",
    "    \n",
    "    return influence_channels\n",
    "\n",
    "def combine_influences(influence_channels):\n",
    "    white_influence = influence_channels[:6].sum(dim=0)\n",
    "    black_influence = influence_channels[6:12].sum(dim=0)\n",
    "    \n",
    "    return {\n",
    "        'total_influence': (white_influence + black_influence).sum().item(),\n",
    "        'control': torch.tanh(white_influence - black_influence).mean().item(),\n",
    "        'tension': torch.min(white_influence, black_influence).sum().item(),\n",
    "        'white_mobility': influence_channels[:6].sum().item(),\n",
    "        'black_mobility': influence_channels[6:12].sum().item(),\n",
    "        'influence_distribution': (white_influence + black_influence).flatten().numpy().tolist(),\n",
    "        'white_influence': white_influence.numpy().tolist(),\n",
    "        'black_influence': black_influence.numpy().tolist()\n",
    "    }\n",
    "\n",
    "def create_jepa_mask(influence_map, mask_ratio=0.25, min_region_size=2, max_region_size=4):\n",
    "    num_squares = influence_map.numel()\n",
    "    num_masked = int(num_squares * mask_ratio)\n",
    "    \n",
    "    _, indices = torch.topk(influence_map.flatten(), k=num_masked)\n",
    "    mask = torch.ones_like(influence_map, dtype=torch.bool)\n",
    "    mask.view(-1)[indices] = False\n",
    "    \n",
    "    for _ in range(max_region_size - 1):\n",
    "        expanded_mask = torch.nn.functional.max_pool2d(\n",
    "            (~mask).float().unsqueeze(0).unsqueeze(0),\n",
    "            kernel_size=3, stride=1, padding=1\n",
    "        ).squeeze(0).squeeze(0).bool()\n",
    "        mask = ~expanded_mask\n",
    "        \n",
    "        if (~mask).sum() >= num_masked * max_region_size / min_region_size:\n",
    "            break\n",
    "    \n",
    "    excess = (~mask).sum() - num_masked\n",
    "    if excess > 0:\n",
    "        trim_indices = torch.randperm((~mask).sum())[:excess]\n",
    "        mask[~mask] |= torch.zeros((~mask).sum(), dtype=torch.bool).scatter_(0, trim_indices, True)\n",
    "    \n",
    "    return mask.numpy().tolist()\n",
    "\n",
    "def find_critical_moments(history: Dict[str, List[float]], threshold: float = 0.5) -> List[int]:\n",
    "    control_changes = [abs(history['control'][i+1] - history['control'][i]) for i in range(len(history['control']) - 1)]\n",
    "    critical_moments = [i for i, change in enumerate(control_changes) if change > threshold]\n",
    "    return critical_moments\n",
    "\n",
    "def analyze_game_sequence(moves: List[str], engine_path: str) -> Dict[str, List[float]]:\n",
    "    board = chess.Board()\n",
    "    history = {\n",
    "        'stockfish_eval': [],\n",
    "        'control': [],\n",
    "        'total_influence': [],\n",
    "        'tension': [],\n",
    "        'white_mobility': [],\n",
    "        'black_mobility': [],\n",
    "        'js_divergence': [],\n",
    "        'white_influence': [],\n",
    "        'black_influence': [],\n",
    "        'jepa_mask': [],\n",
    "        'influence_distribution': []\n",
    "    }\n",
    "    prev_distribution = None\n",
    "    \n",
    "    with chess.engine.SimpleEngine.popen_uci(engine_path) as engine:\n",
    "        for move in moves:\n",
    "            try:\n",
    "                board.push_san(move)\n",
    "            except ValueError as e:\n",
    "                print(f\"Error processing move {move}: {e}\")\n",
    "                print(f\"Current board state:\\n{board}\")\n",
    "                break\n",
    "            \n",
    "            metrics = analyze_position(board, engine)\n",
    "            for key in history.keys():\n",
    "                if key in metrics:\n",
    "                    history[key].append(metrics[key])\n",
    "                elif key == 'js_divergence':\n",
    "                    if prev_distribution is not None:\n",
    "                        history[key].append(jensenshannon(metrics['influence_distribution'], prev_distribution))\n",
    "                    else:\n",
    "                        history[key].append(0)\n",
    "            \n",
    "            prev_distribution = metrics['influence_distribution']\n",
    "    \n",
    "    history['critical_moments'] = find_critical_moments(history)\n",
    "    return history\n",
    "\n",
    "def analyze_position(board, engine):\n",
    "    board_tensor = board_to_tensor(board)\n",
    "    influence_channels = create_influence_channels(board_tensor)\n",
    "    metrics = combine_influences(influence_channels)\n",
    "    \n",
    "    result = engine.analyse(board, chess.engine.Limit(time=0.1))\n",
    "    eval_score = result['score'].relative.score(mate_score=10000)\n",
    "    metrics['stockfish_eval'] = eval_score if eval_score is not None else 0\n",
    "    \n",
    "    metrics['jepa_mask'] = create_jepa_mask(torch.tensor(metrics['influence_distribution']).reshape(8, 8))\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "# Analyze games\n",
    "alphazero_moves = [\n",
    "    \"Nf3\", \"Nf6\", \"c4\", \"e6\", \"Nc3\", \"Bb4\", \"Qc2\", \"O-O\", \"a3\", \"Bxc3\", \"Qxc3\", \"a5\", \"b4\", \"d6\", \"e3\", \"Ne4\",\n",
    "    \"Qc2\", \"Ng5\", \"b5\", \"Nxf3+\", \"gxf3\", \"Qf6\", \"d4\", \"Qxf3\", \"Rg1\", \"Nd7\", \"Be2\", \"Qf6\", \"Bb2\", \"Qh4\", \"Rg4\",\n",
    "    \"Qxh2\", \"Rg3\", \"f5\", \"O-O-O\", \"Rf7\", \"Bf3\", \"Qh4\", \"Rh1\", \"Qf6\", \"Kb1\", \"g6\", \"Rgg1\", \"a4\", \"Ka1\", \"Rg7\",\n",
    "    \"e4\", \"f4\", \"c5\", \"Qe7\", \"Rc1\", \"Nf6\", \"e5\", \"dxe5\", \"Rhe1\", \"e4\", \"Bxe4\", \"Qf8\", \"d5\", \"exd5\", \"Bd3\",\n",
    "    \"Bg4\", \"f3\", \"Bd7\", \"Qc3\", \"Nh5\", \"Re5\", \"c6\", \"Rce1\", \"Nf6\", \"Qd4\", \"cxb5\", \"Bb1\", \"Bc6\", \"Re6\", \"Rf7\",\n",
    "    \"Rg1\", \"Qg7\", \"Qxf4\", \"Re8\", \"Rd6\", \"Nd7\", \"Qc1\", \"Rf6\", \"f4\", \"Qe7\", \"Rxf6\", \"Nxf6\", \"f5\", \"Qe3\", \"fxg6\",\n",
    "    \"Qxc1\", \"gxh7+\", \"Kf7\", \"Rxc1\", \"Nxh7\", \"Bxh7\", \"Re3\", \"Rd1\", \"Ke8\", \"Ka2\", \"Bd7\", \"Bd4\", \"Rh3\", \"Bc2\",\n",
    "    \"Be6\", \"Re1\", \"Kd7\", \"Kb2\", \"Rf3\", \"Re5\", \"Rg3\", \"Re3\", \"Rg2\", \"Kc3\", \"Rg4\", \"Rf3\", \"Ke8\", \"Rf2\", \"Rg3+\",\n",
    "    \"Kb4\", \"Rg4\", \"Rd2\", \"Bd7\", \"Ka5\", \"Rf4\", \"Be5\", \"Rf3\", \"Rd3\", \"Rf2\", \"Bd1\", \"Bc6\", \"Kb6\"\n",
    "]\n",
    "\n",
    "vladimir_moves = [\n",
    "    \"d4\", \"Nf6\", \"c4\", \"e6\", \"Nc3\", \"Bb4\", \"e3\", \"O-O\", \"Bd3\", \"d5\", \"Nf3\", \"c5\", \"O-O\", \"cxd4\", \"exd4\", \"dxc4\",\n",
    "    \"Bxc4\", \"b6\", \"Bg5\", \"Bb7\", \"Re1\", \"Nbd7\", \"Rc1\", \"Rc8\", \"Qb3\", \"Be7\", \"Bxf6\", \"Nxf6\", \"Bxe6\", \"fxe6\",\n",
    "    \"Qxe6+\", \"Kh8\", \"Qxe7\", \"Bxf3\", \"gxf3\", \"Qxd4\", \"Nb5\", \"Qxb2\", \"Rxc8\", \"Rxc8\", \"Nd6\", \"Rb8\", \"Nf7+\", \"Kg8\",\n",
    "    \"Qe6\", \"Rf8\", \"Nd8+\", \"Kh8\", \"Qe7\"\n",
    "]\n",
    "\n",
    "stockfish_path = r\"C:\\Users\\Windows\\chess_engines\\stockfish\\stockfish-windows-x86-64-avx2.exe\"\n",
    "\n",
    "games = {'AlphaZero': alphazero_moves, 'Vladimir': vladimir_moves}\n",
    "histories = {name: analyze_game_sequence(moves, stockfish_path) for name, moves in games.items()}\n",
    "\n",
    "# Convert data to JSON for JavaScript visualization\n",
    "with open('chess_analysis_data.json', 'w') as f:\n",
    "    json.dump(histories, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default_pt_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
